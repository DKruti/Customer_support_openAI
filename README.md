# Customer_support_openAI
**Customer Support System Using ChatGPT and OpenAI API**

## Table of Contents
1. [Introduction](#introduction)
2. [Design](#design)
3. [Implementation](#implementation)
4. [Test](#test)
5. [Enhancement Ideas](#enhancement-ideas)
6. [Conclusion](#conclusion)
7. [Bibliography / References](#bibliography--references)

## Introduction

- To satisfy the need of the customer using Leveraging Artificial Intelligence for enhanced support, the application is developed.
- Used OpenAI API_key and Org_ID to use OpenAI API. For that, an account is created and set the key and org_id, then credit the balance to use its API.
- The objective is to develop a web-based and command-based application for website-related queries. If information is mentioned on that website, it prints the answer; otherwise, it prints "Don't know."
- Key Technologies: ChatGPT by OpenAI, Python Flask, and Node.js.

## Project Phases

Three phases:

1. **Phase 1: Data Collation - Gathering information from various sources**
   - Data can be in any form: Webpages, Local Files, Database, Videos, Drives.
   - For this first project, web pages are used.

2. **Phase 2: Training - Preparing ChatGPT project for effective response**
   - Training can be done using files, API, and Fine-tuning.
   - For this first project, ChatGPT API is used.

3. **Phase 3: User Interface - output method**
   - Text message or Speech.
   - For this project, text message is used.

## Design

To achieve full functionality, follow these steps:

1. **Crawler [Data collection]:** In this step, pass the given website or page link as a domain, and then it crawls the website. It generates a .csv file with all the website crawling information and stores it with the name "Scraped.csv."

2. **Embedding [Model Training]:** Once you have gathered a substantial dataset, proceed to the embedding phase, which involves training an NLP model like GPT (Generative Pre-trained Transformer) on this data. The model learns to understand the patterns, relationships, and semantics present in the text data through a process called "embedding." Here, an "embeddings.csv" file is generated.

3. **Testing:** The output is generated by combining the above 2 methods using a Question - Answers model, either by command line argument or GUI-based method.

## Implementation Error and Solution

1. Do not require to create a new virtual environment every time. If you created a venv successfully in homework-1, then directly write the command
    **`workon <your venv name>` (For Example, `workon chatgpt`).**

2. Just run your `crawler.py`, `embedding.py`, and `app.py` files like a normal executing python file:
   ```shell
   **python3 crawler.py**
3.  It gives suggestions to install supported packages. and installed it using 
   **pip3 install <suggested package_name>**
   **Repeat step 2 & 3 until it runs successfully and try for embedding.py as well**
4. Run python3 embedding.py
5. Run Appfile which is commandApp.py or webApp.py either to execute application command based or web based using
   **python3 commandApp.py** or **python3 webApp.py**
6. Test the application while asking questions for Example: "what is the model name?" then submit you get answer. If content are not available it display "I don't know"
